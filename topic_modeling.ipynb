{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we will perform the word embedding & topic modeling & Cosine Similarity\n",
    "\n",
    "***we merged the **three** chapters to perform the topic modeling, in order to perform cosine similarity to select which chapter the new input should go with.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data and pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02 = pd.read_csv('chapters_4rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the stop words list with pickle\n",
    "with open ('stop_words.ob', 'rb') as fp:\n",
    "    stop_words = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['string_values'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list that is to be converted into a column\n",
    "ch_no = ['cardiovascular', 'neurologic', 'renal']\n",
    " \n",
    "# Using 'ch_no' as the column name\n",
    "# and equating it to the list\n",
    "df02['Ch_No'] = ch_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_values</th>\n",
       "      <th>Ch_No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>introduction fetus barely cease end life defin...</td>\n",
       "      <td>cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>introduction communication network coordinate ...</td>\n",
       "      <td>neurologic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>introduction kidney located retroperitoneally ...</td>\n",
       "      <td>renal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       string_values           Ch_No\n",
       "0  introduction fetus barely cease end life defin...  cardiovascular\n",
       "1  introduction communication network coordinate ...      neurologic\n",
       "2  introduction kidney located retroperitoneally ...           renal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    introduction fetus barely cease end life defin...\n",
       "1    introduction communication network coordinate ...\n",
       "2    introduction kidney located retroperitoneally ...\n",
       "Name: string_values, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df02['string_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinku\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['60', 'beta', 'salt', 'self', 'sn', 'sodium'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer for parsing/counting words\n",
    "count_vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "doc_word_cv = count_vectorizer.fit_transform(df02['string_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abates</th>\n",
       "      <th>abbokinase</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomenjunction</th>\n",
       "      <th>abduc</th>\n",
       "      <th>aberrant</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablation</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>younge</th>\n",
       "      <th>zazulia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoster</th>\n",
       "      <th>μl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cardiovascular</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurologic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                aaa  ab  abates  abbokinase  abdomen  abdomenjunction  abduc  \\\n",
       "Ch_No                                                                          \n",
       "cardiovascular    6   3       0           1        2                0      0   \n",
       "neurologic        0   0       0           0        0                0      1   \n",
       "renal             0   0       1           0        0                1      0   \n",
       "\n",
       "                aberrant  ability  ablation  ...  yoga  york  younge  zazulia  \\\n",
       "Ch_No                                        ...                                \n",
       "cardiovascular         0        6         2  ...     0     0       1        0   \n",
       "neurologic             1       12         0  ...     1     1       0        1   \n",
       "renal                  0        3         2  ...     0     4       1        0   \n",
       "\n",
       "                zealand  zigzag  zinc  zone  zoster  μl  \n",
       "Ch_No                                                    \n",
       "cardiovascular        0       0     1     0       0   0  \n",
       "neurologic            1       1     0     4       2   0  \n",
       "renal                 0       0     0     1       1   1  \n",
       "\n",
       "[3 rows x 5714 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(doc_word_cv.toarray(), index=df02['Ch_No'], columns = count_vectorizer.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rinku\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['60', 'beta', 'salt', 'self', 'sn', 'sodium'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a TfidfVectorizer for parsing/counting words\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "doc_word_tfidf = tfidf.fit_transform(df02['string_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>abates</th>\n",
       "      <th>abbokinase</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomenjunction</th>\n",
       "      <th>abduc</th>\n",
       "      <th>aberrant</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablation</th>\n",
       "      <th>...</th>\n",
       "      <th>yoga</th>\n",
       "      <th>york</th>\n",
       "      <th>younge</th>\n",
       "      <th>zazulia</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoster</th>\n",
       "      <th>μl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ch_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cardiovascular</th>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neurologic</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.025520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     aaa        ab    abates  abbokinase   abdomen  \\\n",
       "Ch_No                                                                \n",
       "cardiovascular  0.019473  0.009737  0.000000    0.003246  0.006491   \n",
       "neurologic      0.000000  0.000000  0.000000    0.000000  0.000000   \n",
       "renal           0.000000  0.000000  0.004275    0.000000  0.000000   \n",
       "\n",
       "                abdomenjunction     abduc  aberrant   ability  ablation  ...  \\\n",
       "Ch_No                                                                    ...   \n",
       "cardiovascular         0.000000  0.000000  0.000000  0.011501  0.004937  ...   \n",
       "neurologic             0.000000  0.003601  0.003601  0.025520  0.000000  ...   \n",
       "renal                  0.004275  0.000000  0.000000  0.007575  0.006503  ...   \n",
       "\n",
       "                    yoga      york    younge   zazulia   zealand    zigzag  \\\n",
       "Ch_No                                                                        \n",
       "cardiovascular  0.000000  0.000000  0.002468  0.000000  0.000000  0.000000   \n",
       "neurologic      0.003601  0.002738  0.000000  0.003601  0.003601  0.003601   \n",
       "renal           0.000000  0.013006  0.003251  0.000000  0.000000  0.000000   \n",
       "\n",
       "                    zinc      zone    zoster        μl  \n",
       "Ch_No                                                   \n",
       "cardiovascular  0.003246  0.000000  0.000000  0.000000  \n",
       "neurologic      0.000000  0.010954  0.005477  0.000000  \n",
       "renal           0.000000  0.003251  0.003251  0.004275  \n",
       "\n",
       "[3 rows x 5714 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(doc_word_tfidf.toarray(), index=df02['Ch_No'], columns = tfidf.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling: **LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "corpus = matutils.Sparse2Corpus(doc_word_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lda model (equivalent to \"fit\" in sklearn)\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=3, id2word=id2word, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.814*\"ab\" + 0.015*\"aaa\" + 0.015*\"abates\" + 0.000*\"pick\" + 0.000*\"physiology\" + 0.000*\"physiotherapy\" + 0.000*\"physician\" + 0.000*\"picking\" + 0.000*\"pig\" + 0.000*\"pickle\"'),\n",
       " (1,\n",
       "  '0.788*\"abates\" + 0.003*\"ab\" + 0.002*\"aaa\" + 0.000*\"pick\" + 0.000*\"physiology\" + 0.000*\"physiotherapy\" + 0.000*\"physician\" + 0.000*\"picking\" + 0.000*\"pig\" + 0.000*\"pickle\"'),\n",
       " (2,\n",
       "  '0.816*\"aaa\" + 0.023*\"abates\" + 0.017*\"ab\" + 0.000*\"pick\" + 0.000*\"physiology\" + 0.000*\"physiotherapy\" + 0.000*\"physician\" + 0.000*\"picking\" + 0.000*\"pig\" + 0.000*\"pickle\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing CorEx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "\n",
    "words = list(np.asarray(count_vectorizer.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Some words never appear (or always appear)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<corextopic.corextopic.Corex at 0x219e40161d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model = ct.Corex(n_hidden=3, words=words, seed=1)\n",
    "topic_model.fit(doc_word_cv, words=words, docs=df02['string_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: abduc,numbered,ntilation,nt,nourishment,notepad,nostril,nortriptyline,nonirritating,noniodinated\n",
      "1: aaa,significance,signify,initiating,signsand,inhibition,inhibit,silhouette,sighing,since\n",
      "2: abates,nephrosclerosis,nephropathy,nephron,nephrologists,nephrolithiasis,nephrocalcinosis,nephritis,nephrectomy,necessitate\n"
     ]
    }
   ],
   "source": [
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling: LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10451465 0.5101165  0.38536885]\n"
     ]
    }
   ],
   "source": [
    "lsa = TruncatedSVD(3)\n",
    "doc_topic = lsa.fit_transform(doc_word_cv)\n",
    "print(lsa.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              aaa     ab  abates  abbokinase  abdomen  abdomenjunction  abduc  \\\n",
      "component0  0.009  0.004   0.001       0.001    0.003            0.001  0.001   \n",
      "component1 -0.011 -0.005   0.000      -0.002   -0.004            0.000  0.002   \n",
      "component2 -0.005 -0.002   0.003      -0.001   -0.002            0.003 -0.001   \n",
      "\n",
      "            aberrant  ability  ablation  ...   yoga   york  younge  zazulia  \\\n",
      "component0     0.001    0.023     0.004  ...  0.001  0.004   0.002    0.001   \n",
      "component1     0.002    0.017    -0.003  ...  0.002  0.003  -0.002    0.002   \n",
      "component2    -0.001   -0.005     0.005  ... -0.001  0.011   0.002   -0.001   \n",
      "\n",
      "            zealand  zigzag   zinc   zone  zoster     μl  \n",
      "component0    0.001   0.001  0.001  0.005   0.003  0.001  \n",
      "component1    0.002   0.002 -0.002  0.009   0.005  0.000  \n",
      "component2   -0.001  -0.001 -0.001 -0.000   0.001  0.003  \n",
      "\n",
      "[3 rows x 5714 columns]\n"
     ]
    }
   ],
   "source": [
    "topic_word = pd.DataFrame(lsa.components_.round(3),\n",
    "             index = ['component'+str(i) for i in range(3)],\n",
    "             columns = count_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_list = [] \n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    \n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        inner_tem_list = []\n",
    "       \n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "            \n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        inner_tem_list.append(\", \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        tem_list.append(inner_tem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "artery, aneurysm, brain, muscle, valve, arrhythmia, defect, ventricle, seizure, aorta, kidney, bladder, motor, headache, stroke, leg, medication, vessel, intake, ecg, infarction, hypertrophy, case, hemorrhage, endocarditis, weakness, ischemia, dysfunction, encephalitis, catheterization, oxygen, occlusion, shock, page, onset, obstruction, arm, insufficiency, circulation, vomiting, rupture, dyspnea, bleeding, shunt, cord, pericarditis, virus, tract, wave, caused, vsd, abnormality, icp, size, diet, reveals, calculus, echocardiography, two, thrombosis, qrs, monitoring, prognosis, eye, status, csf, contraction, tachycardia, follow, attack, detect, sodium, sinus, protein, carefully, place, neck, atrium, must, possibly, nausea, rarely, temperature, stenosis, eventually, study, neuron, pacemaker, hypotension, fatigue, dialysis, state, meningitis, block, abscess, smoking, prevention, food, resistance, men, generally, po, line, calcium, become, three, pda, phase, occasionally, identify, illness, potassium, woman, toxicity, advise, agent, problem, performed, deficit, branch, stop, fibrillation, birth, myocarditis, coarctation, blocker, rise, perfusion, water, location, ask, goal, tumor, minute, conduction, determine, depending, mri, auscultation, layer, balloon, mechanism, loc, allows, consists, mouth, appear, repair, take, rapidly\n",
      "\n",
      "Topic  1\n",
      "brain, seizure, muscle, motor, headache, encephalitis, cord, icp, csf, virus, eye, neuron, meningitis, weakness, stroke, abscess, hemorrhage, mouth, illness, onset, coma, deficit, case, cp, ct, paralysis, attack, tumor, lobe, speech, avm, rigidity, bladder, difficulty, ask, face, gravis, parkinson, vomiting, food, sensation, problem, caused, behavior, tremor, alzheimer, skull, impairment, loc, assist, puncture, fiber, information, place, neck, part, cjd, bell, contracture, dementia, transmission, avms, exacerbation, reye, well, testing, become, root, glucose, mri, sleep, feeding, ataxia, disturbance, protein, lack, vision, eat, meal, irritability, tongue, memory, assessment, louis, hemisphere, huntington, personality, neuralgia, recovery, given, confusion, degeneration, process, malformation, range, demyelination, neuritis, bleed, refer, status, transmitted, remove, tone, severity, inability, nausea, aspiration, cortex, swallowing, rule, drowsiness, vaccine, teeth, remission, stimulus, strength, extremity, equine, axon, move, atrophy, deterioration, water, method, vessel, suggests, establish, member, state, eeg, receptor, sclerosis, coordination, score, chewing, sheath, taste, tract, point, gait, ptosis, room, bird, mine, cross, crp, matter, ganglion, wee, varies\n",
      "\n",
      "Topic  2\n",
      "bladder, kidney, calculus, dialysis, obstruction, sodium, reflux, uti, stone, potassium, pyelonephritis, hydronephrosis, hematuria, prostate, contrast, voiding, prostatitis, bacteria, diet, protein, glomerulonephritis, specimen, acidosis, intake, rta, tubule, calcium, woman, scan, anemia, tip, men, water, substance, bicarbonate, metabolic, rbc, proteinuria, urination, atn, anomaly, urinalysis, utis, epididymitis, bph, thrombosis, chill, bleeding, creatinine, pediatric, tract, gi, orifice, transplantation, incontinence, imbalance, membrane, gfr, clearance, observe, excretion, parenchyma, laboratory, stenosis, stricture, glomerulus, hydration, aki, access, gravity, hyperkalemia, solution, reaction, collecting, apsgn, sample, calyx, nitrogen, collection, oliguria, allow, carefully, even, diverticulum, nephron, bag, cyst, sensitivity, method, well, aldosterone, angiotensin, orchitis, enlargement, vitamin, production, material, organism, per, rarely, reabsorption, retention, medication, correct, cystoscopy, duct, fistula, urea, wbc, necessitate, value, frequency, preventing, passage, juice, pyramid, emptying, instruct, necrosis, exchange, urgency, presence, performed, eventually, containing, plexus, bath, biopsy, particularly, balance, infarction, cystourethrography, none, dialysate, midstream, secrete, hb, plan, resection, infusion, cavity, caused, pyuria, filtration, renin, outlet, food, overload, stasis, hormone\n"
     ]
    }
   ],
   "source": [
    "result1 = display_topics(lsa, count_vectorizer.get_feature_names_out(), 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_list\n",
    "final_dic = {}\n",
    "final_dic[\"Cardio\"] = tem_list[0]\n",
    "final_dic[\"Neuro\"] = tem_list[1]\n",
    "final_dic[\"Renal\"] = tem_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cardio': ['artery, aneurysm, brain, muscle, valve, arrhythmia, defect, ventricle, seizure, aorta, kidney, bladder, motor, headache, stroke, leg, medication, vessel, intake, ecg, infarction, hypertrophy, case, hemorrhage, endocarditis, weakness, ischemia, dysfunction, encephalitis, catheterization, oxygen, occlusion, shock, page, onset, obstruction, arm, insufficiency, circulation, vomiting, rupture, dyspnea, bleeding, shunt, cord, pericarditis, virus, tract, wave, caused, vsd, abnormality, icp, size, diet, reveals, calculus, echocardiography, two, thrombosis, qrs, monitoring, prognosis, eye, status, csf, contraction, tachycardia, follow, attack, detect, sodium, sinus, protein, carefully, place, neck, atrium, must, possibly, nausea, rarely, temperature, stenosis, eventually, study, neuron, pacemaker, hypotension, fatigue, dialysis, state, meningitis, block, abscess, smoking, prevention, food, resistance, men, generally, po, line, calcium, become, three, pda, phase, occasionally, identify, illness, potassium, woman, toxicity, advise, agent, problem, performed, deficit, branch, stop, fibrillation, birth, myocarditis, coarctation, blocker, rise, perfusion, water, location, ask, goal, tumor, minute, conduction, determine, depending, mri, auscultation, layer, balloon, mechanism, loc, allows, consists, mouth, appear, repair, take, rapidly'],\n",
       " 'Neuro': ['brain, seizure, muscle, motor, headache, encephalitis, cord, icp, csf, virus, eye, neuron, meningitis, weakness, stroke, abscess, hemorrhage, mouth, illness, onset, coma, deficit, case, cp, ct, paralysis, attack, tumor, lobe, speech, avm, rigidity, bladder, difficulty, ask, face, gravis, parkinson, vomiting, food, sensation, problem, caused, behavior, tremor, alzheimer, skull, impairment, loc, assist, puncture, fiber, information, place, neck, part, cjd, bell, contracture, dementia, transmission, avms, exacerbation, reye, well, testing, become, root, glucose, mri, sleep, feeding, ataxia, disturbance, protein, lack, vision, eat, meal, irritability, tongue, memory, assessment, louis, hemisphere, huntington, personality, neuralgia, recovery, given, confusion, degeneration, process, malformation, range, demyelination, neuritis, bleed, refer, status, transmitted, remove, tone, severity, inability, nausea, aspiration, cortex, swallowing, rule, drowsiness, vaccine, teeth, remission, stimulus, strength, extremity, equine, axon, move, atrophy, deterioration, water, method, vessel, suggests, establish, member, state, eeg, receptor, sclerosis, coordination, score, chewing, sheath, taste, tract, point, gait, ptosis, room, bird, mine, cross, crp, matter, ganglion, wee, varies'],\n",
       " 'Renal': ['bladder, kidney, calculus, dialysis, obstruction, sodium, reflux, uti, stone, potassium, pyelonephritis, hydronephrosis, hematuria, prostate, contrast, voiding, prostatitis, bacteria, diet, protein, glomerulonephritis, specimen, acidosis, intake, rta, tubule, calcium, woman, scan, anemia, tip, men, water, substance, bicarbonate, metabolic, rbc, proteinuria, urination, atn, anomaly, urinalysis, utis, epididymitis, bph, thrombosis, chill, bleeding, creatinine, pediatric, tract, gi, orifice, transplantation, incontinence, imbalance, membrane, gfr, clearance, observe, excretion, parenchyma, laboratory, stenosis, stricture, glomerulus, hydration, aki, access, gravity, hyperkalemia, solution, reaction, collecting, apsgn, sample, calyx, nitrogen, collection, oliguria, allow, carefully, even, diverticulum, nephron, bag, cyst, sensitivity, method, well, aldosterone, angiotensin, orchitis, enlargement, vitamin, production, material, organism, per, rarely, reabsorption, retention, medication, correct, cystoscopy, duct, fistula, urea, wbc, necessitate, value, frequency, preventing, passage, juice, pyramid, emptying, instruct, necrosis, exchange, urgency, presence, performed, eventually, containing, plexus, bath, biopsy, particularly, balance, infarction, cystourethrography, none, dialysate, midstream, secrete, hb, plan, resection, infusion, cavity, caused, pyuria, filtration, renin, outlet, food, overload, stasis, hormone']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cardio</th>\n",
       "      <td>artery, aneurysm, brain, muscle, valve, arrhyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuro</th>\n",
       "      <td>brain, seizure, muscle, motor, headache, encep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Renal</th>\n",
       "      <td>bladder, kidney, calculus, dialysis, obstructi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "Cardio  artery, aneurysm, brain, muscle, valve, arrhyt...\n",
       "Neuro   brain, seizure, muscle, motor, headache, encep...\n",
       "Renal   bladder, kidney, calculus, dialysis, obstructi..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_df = pd.DataFrame.from_dict(final_dic, orient ='index') \n",
    "tem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a list that is to be converted into a column\n",
    "\n",
    " \n",
    "# Using 'ch_no' as the column name\n",
    "# and equating it to the list\n",
    "tem_df['Disease_Name'] = ch_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 'Disease_Name'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Disease_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cardio</th>\n",
       "      <td>artery, aneurysm, brain, muscle, valve, arrhyt...</td>\n",
       "      <td>cardiovascular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuro</th>\n",
       "      <td>brain, seizure, muscle, motor, headache, encep...</td>\n",
       "      <td>neurologic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Renal</th>\n",
       "      <td>bladder, kidney, calculus, dialysis, obstructi...</td>\n",
       "      <td>renal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Description    Disease_Name\n",
       "Cardio  artery, aneurysm, brain, muscle, valve, arrhyt...  cardiovascular\n",
       "Neuro   brain, seizure, muscle, motor, headache, encep...      neurologic\n",
       "Renal   bladder, kidney, calculus, dialysis, obstructi...           renal"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_df = tem_df.rename(columns={0: 'Description'})\n",
    "tem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem_df.to_csv('diseases_with_description.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e20053a6a21f60b20031b0e753dd017cb749c39f38e8781debb23d87a774e1c7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
